{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vggish trained on melspectograms.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nge_q1lAb2tN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJG3PK9Ub7QJ",
        "colab_type": "text"
      },
      "source": [
        "### **MEL Spectograms Method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2N9bby6b_kL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from vggish_input import waveform_to_examples\n",
        "\n",
        "path = \"/content/drive/My Drive/small_dataset/not_sick/Copy of audioset_EQzYcBJ1Dec_100_105.wav\"\n",
        "\n",
        "sr = 22100\n",
        "signal, sr = librosa.load(path, sr)\n",
        "\n",
        "S = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=128, fmax=8000)\n",
        "S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "print(S_dB.shape)\n",
        "print(S.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqF8WP2AcAJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(S_dB, x_axis='time',\n",
        "                          y_axis='mel', sr=sr,\n",
        "                          fmax=8000)\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Mel-frequency spectrogram')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AECTCnw-cALc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combining embeddings and mfcc\n",
        "\n",
        "import os \n",
        "import librosa\n",
        "import math\n",
        "import json\n",
        "from vggish_input import waveform_to_examples\n",
        "\n",
        "DATASET_PATH = \"/content/drive/My Drive/test_dataset\"\n",
        "JSON_PATH = \"data5.json\"\n",
        "SAMPLE_RATE = 22050\n",
        "DURATION = 4  # measured in seconds.\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
        "\n",
        "def save_mfcc(dataset_path, json_path, n_mfcc = 13, n_fft = 2048, hop_length= 512, num_segments = 5):\n",
        "   \n",
        "    data = {\n",
        "        \"mapping\": [],\n",
        "        \"spectograms\": [],\n",
        "        \"labels\": []\n",
        "    }\n",
        "    \n",
        "    num_samples_per_segment =  int(SAMPLES_PER_TRACK / num_segments)\n",
        "    \n",
        "    expected_no_of_mfcc_vectors_per_segment = math.ceil(num_samples_per_segment / hop_length) \n",
        "    # 1) Loop through all the genres\n",
        "    for i, (dirpath, dirname, filenames) in enumerate(os.walk(dataset_path)):\n",
        "    # dirpath is the current path/folder we r in.\n",
        "    # dirname are all the name of the subfolders. \n",
        "    # filenames are all the files that we have in dirpath.\n",
        "        \n",
        "        # Ensure that we r not at the root level\n",
        "        if dirpath is not dataset_path:\n",
        "            # save the semantic labels\n",
        "            # sematic labels --> mapping contains semantic labels. e.g on 0 we have classical, on 1 we have blues etc\n",
        "            dirpath_components = dirpath.split(\"\\\\\")  # \"genre/blues\" => [\"genre\", \"blues\"]\n",
        "            semantic_label = dirpath_components[-1]\n",
        "            data[\"mapping\"].append(semantic_label)\n",
        "            \n",
        "            print(\"\\n Processing {}\".format(semantic_label))\n",
        "            \n",
        "            # Process files for specific genre. \n",
        "            for f in filenames:\n",
        "                # f just give us the name of the file it doesnt give us the full path.\n",
        "                # we need full path for loading the file so for loading full path we do\n",
        "                \n",
        "                # laoding audio file\n",
        "                file_path = os.path.join(dirpath, f)\n",
        "                signal, sr = librosa.load(file_path, sr = SAMPLE_RATE)\n",
        "                # we can't anaylyze mfcc's at this level blc we have broken our song into small chunks/segments\n",
        "                # so we have to analyze mfcc's at segment level. so for this, we have to divide our signal/sound into bunch\n",
        "                # of segments.\n",
        "                \n",
        "                # divide signals into segments,process segments, extract mfcc and at last store mfcc vectors.\n",
        "                for s in range(num_segments):\n",
        "                    \n",
        "                    start_sample = num_samples_per_segment * s  # if s= 0 -> then start_sample = 0 \n",
        "                    finish_sample = start_sample + num_samples_per_segment  # if s=0 -> num_segments_per_sample\n",
        "                    \n",
        "                    # mfcc = waveform_to_examples(signal[start_sample: finish_sample], sr)\n",
        "                    S = librosa.feature.melspectrogram(y=signal[start_sample: finish_sample], sr=sr, n_mels=128, fmax=8000)\n",
        "                    mfcc = librosa.power_to_db(S, ref=np.max)\n",
        "                    \n",
        "                    mfcc = mfcc.T \n",
        "\n",
        "                    # store mfcc vector for each segment, if it has the expected length. \n",
        "                    data[\"spectograms\"].append(mfcc.tolist()) # we can not append mfcc directly blc its a numpy array so we have\n",
        "                        # to first convert it into list.\n",
        "                        \n",
        "                    data[\"labels\"].append(i-1)\n",
        "                        \n",
        "                    print(\"{}, segment : {}\".format(file_path, s))\n",
        "                \n",
        "    # final step: saving everything as a json file            \n",
        "    with open(json_path, \"w\") as fp:\n",
        "        json.dump(data, fp, indent = 4)  # indent mean spaces while writing. fp mean file_path  \n",
        "        \n",
        "        \n",
        "if __name__ == \"__main__\":\n",
        "    save_mfcc(DATASET_PATH, JSON_PATH, num_segments = 4)\n",
        "                \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ETyC50ccXRq",
        "colab_type": "text"
      },
      "source": [
        "#### **Model trained on Mel Spectograms**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I5fREb_cAOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from preprocess_sound import preprocess_sound\n",
        "import numpy as np\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Flatten, Input, Dense, GlobalMaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D, BatchNormalization, Dropout\n",
        "from vggish import VGGish\n",
        "from preprocess_sound import preprocess_sound\n",
        "\n",
        "\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATASET_PATH = \"/content/data5.json\"\n",
        "\n",
        "def load_data(dataset_path):\n",
        "    with open(dataset_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "        \n",
        "        \n",
        "    # converting lists into numpy arrays\n",
        "    X = np.array(data[\"spectograms\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "def prepare_datasets(test_size, validation_size):\n",
        "    \n",
        "    # load dataset\n",
        "    X, y = load_data(DATASET_PATH)\n",
        "    \n",
        "    # create train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=42)\n",
        "    \n",
        "    # create train/validataion split\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size= validation_size, random_state=32)\n",
        "    \n",
        "    print(X_train.shape)\n",
        "    \n",
        "    # so in X_train we have 3d array --> (sample_size, mfcc_vector, mfcc_coefficient)\n",
        "    # so we have to introduce another dimension in it. and make it 4d array. \n",
        "    X_train = X_train[... , np.newaxis]\n",
        "    # ... 3dots mean keep the rest of the shape same.\n",
        "    X_validation = X_validation[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "    \n",
        "    print(X_train.shape)\n",
        "    print(X_validation.shape)\n",
        "    print(X_test.shape)\n",
        "    \n",
        "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n",
        "\n",
        "def plot_history(history):\n",
        "    \n",
        "    fig, axis = plt.subplots(2)\n",
        "    \n",
        "    # create accuracy subplot\n",
        "    axis[0].plot(history.history[\"accuracy\"], label = \"train accuracy\" )\n",
        "    axis[0].plot(history.history[\"val_accuracy\"], label = \"test_accuracy\" )\n",
        "    axis[0].set_ylabel(\"Accuracy\")\n",
        "    axis[0].set_xlabel(\"Epochs\")\n",
        "    axis[0].legend(loc = \"lower right\")\n",
        "    axis[0].set_title(\"Acccuracy eval\")\n",
        "    \n",
        "    \n",
        "    # create error subplot\n",
        "    axis[1].plot(history.history[\"loss\"], label = \"train error\" )\n",
        "    axis[1].plot(history.history[\"val_loss\"], label = \"test error\" )\n",
        "    axis[1].set_ylabel(\"Error\")\n",
        "    axis[1].set_xlabel(\"Epochs\")\n",
        "    axis[1].legend(loc = \"upper right\")\n",
        "    axis[1].set_title(\"Error eval\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def predict(model, X, y):\n",
        "    \n",
        "    # add a dimension to input data for sample - model.predict() expects a 4d array in this case\n",
        "    X = X[np.newaxis, ...] # array shape (1, 130, 13, 1)\n",
        "    print(X.shape)\n",
        "\n",
        "    # perform prediction\n",
        "    prediction = model.predict(X)\n",
        "\n",
        "    # get index with max value\n",
        "    predicted_index = np.argmax(prediction, axis=1)\n",
        "\n",
        "    print(\"Target: {}, Predicted label: {}\".format(y, predicted_index))\n",
        "\n",
        "\n",
        "\n",
        "# Create train, validation and test set\n",
        "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.20)\n",
        "\n",
        "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "\n",
        "new_input = Input(shape=(87, 128, 1))\n",
        "sound_model = VGGish(include_top=False, load_weights=True, input_tensor = new_input)\n",
        "\n",
        "for layer in sound_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = sound_model.get_layer(name=\"conv4/conv4_2\").output\n",
        "# x = GlobalMaxPooling2D()(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# x = Flatten()(x)\n",
        "class1 = Dense(1024, activation = 'relu', kernel_regularizer=l2(0.01))(x)\n",
        "class1 = Dropout(0.5)(class1)\n",
        "class2 = Dense(512, activation = 'relu', kernel_regularizer=l2(0.01))(class1)\n",
        "class2 = Dropout(0.5)(class2)\n",
        "class2 = Dense(512, activation = 'relu', kernel_regularizer=l2(0.01))(class2)\n",
        "class2 = Dropout(0.5)(class2)\n",
        "class3 = Dense(256, activation = 'relu', kernel_regularizer=l2(0.01))(class2)\n",
        "outputss = Dense(2, activation = \"softmax\")(class3)\n",
        "\n",
        "# define new model\n",
        "model = Model(input = sound_model.input, output = outputss)\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, mode = \"auto\",\n",
        "                              patience=5, min_delta=0.0001, cooldown=0, min_lr=0.001)\n",
        "\n",
        "early_stoping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=9, verbose=1,\n",
        "              mode='auto', baseline=None, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# compile the network\n",
        "optimizer = optimizers.Adamax(learning_rate=0.0002, beta_1=0.9, beta_2=0.999)\n",
        "model.compile(optimizer = optimizer,\n",
        "              loss = \"sparse_categorical_crossentropy\",\n",
        "              metrics = [\"accuracy\"]\n",
        "              )\n",
        "\n",
        "# train the CNN\n",
        "history = model.fit(X_train,\n",
        "          y_train,\n",
        "          validation_data = (X_validation, y_validation),\n",
        "          batch_size = 32,\n",
        "          epochs = 300,\n",
        "          callbacks = [reduce_lr, early_stoping]\n",
        "          )\n",
        "\n",
        "# plot accuracy/error for training and validation\n",
        "plot_history(history)\n",
        "\n",
        "# evaluate the CNN on the test set\n",
        "test_error, test_accuracy = model.evaluate(X_test, y_test, verbose = 1)\n",
        "print(\"Accuracy on test set is {}\".format(test_accuracy))\n",
        "\n",
        "# pick a sample to predict from the test set\n",
        "X_to_predict = X_test[50]\n",
        "y_to_predict = y_test[50]\n",
        "\n",
        "# predict sample\n",
        "predict(model, X_to_predict, y_to_predict)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0SKU1qqcAP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D97ahl23cAS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}